{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD, LogisticRegressionWithLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/04/12 21:25:14 WARN Utils: Your hostname, minhnhat resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/12 21:25:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/12 21:25:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#pyspark init\n",
    "builder = SparkSession.builder\\\n",
    "            .appName('creditcard_mllib')\\\n",
    "            .config(\"spark.driver.memory\", \"4g\")\\\n",
    "            .config(\"spark.executor.memory\", \"4g\")\n",
    "spark = builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Read input file\n",
    "raw_df = spark.read.csv('creditcard.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to rdd\n",
    "feature_cols = [col for col in raw_df.columns if col != 'Class']\n",
    "\n",
    "data_rdd = raw_df.rdd.map(lambda row: LabeledPoint(\n",
    "    float(row['Class']),\n",
    "    [float(row[col]) for col in feature_cols]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [0.0,-1.3598071336738,-0.0727811733098497,2.53634673796914,1.37815522427443,-0.338320769942518,0.462387777762292,0.239598554061257,0.0986979012610507,0.363786969611213,0.0907941719789316,-0.551599533260813,-0.617800855762348,-0.991389847235408,-0.311169353699879,1.46817697209427,-0.470400525259478,0.207971241929242,0.0257905801985591,0.403992960255733,0.251412098239705,-0.018306777944153,0.277837575558899,-0.110473910188767,0.0669280749146731,0.128539358273528,-0.189114843888824,0.133558376740387,-0.0210530534538215,149.62]),\n",
       " LabeledPoint(0.0, [0.0,1.19185711131486,0.26615071205963,0.16648011335321,0.448154078460911,0.0600176492822243,-0.0823608088155687,-0.0788029833323113,0.0851016549148104,-0.255425128109186,-0.166974414004614,1.61272666105479,1.06523531137287,0.48909501589608,-0.143772296441519,0.635558093258208,0.463917041022171,-0.114804663102346,-0.183361270123994,-0.145783041325259,-0.0690831352230203,-0.225775248033138,-0.638671952771851,0.101288021253234,-0.339846475529127,0.167170404418143,0.125894532368176,-0.00898309914322813,0.0147241691924927,2.69]),\n",
       " LabeledPoint(0.0, [1.0,-1.35835406159823,-1.34016307473609,1.77320934263119,0.379779593034328,-0.503198133318193,1.80049938079263,0.791460956450422,0.247675786588991,-1.51465432260583,0.207642865216696,0.624501459424895,0.066083685268831,0.717292731410831,-0.165945922763554,2.34586494901581,-2.89008319444231,1.10996937869599,-0.121359313195888,-2.26185709530414,0.524979725224404,0.247998153469754,0.771679401917229,0.909412262347719,-0.689280956490685,-0.327641833735251,-0.139096571514147,-0.0553527940384261,-0.0597518405929204,378.66]),\n",
       " LabeledPoint(0.0, [1.0,-0.966271711572087,-0.185226008082898,1.79299333957872,-0.863291275036453,-0.0103088796030823,1.24720316752486,0.23760893977178,0.377435874652262,-1.38702406270197,-0.0549519224713749,-0.226487263835401,0.178228225877303,0.507756869957169,-0.28792374549456,-0.631418117709045,-1.0596472454325,-0.684092786345479,1.96577500349538,-1.2326219700892,-0.208037781160366,-0.108300452035545,0.00527359678253453,-0.190320518742841,-1.17557533186321,0.647376034602038,-0.221928844458407,0.0627228487293033,0.0614576285006353,123.5]),\n",
       " LabeledPoint(0.0, [2.0,-1.15823309349523,0.877736754848451,1.548717846511,0.403033933955121,-0.407193377311653,0.0959214624684256,0.592940745385545,-0.270532677192282,0.817739308235294,0.753074431976354,-0.822842877946363,0.53819555014995,1.3458515932154,-1.11966983471731,0.175121130008994,-0.451449182813529,-0.237033239362776,-0.0381947870352842,0.803486924960175,0.408542360392758,-0.00943069713232919,0.79827849458971,-0.137458079619063,0.141266983824769,-0.206009587619756,0.502292224181569,0.219422229513348,0.215153147499206,69.99])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing sets\n",
    "\n",
    "train_size = 0.8\n",
    "train_rdd, test_rdd = data_rdd.randomSplit([train_size, 1 - train_size], seed=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/12 21:25:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "\n",
    "model = LogisticRegressionWithLBFGS().train(train_rdd, iterations=iterations, intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-4.1734877493517316e-06,0.07662392514300612,0.042576005566222104,-0.0025974604475015716,0.728117805028605,0.1548178159566063,-0.10603229688637944,-0.06652750049964885,-0.17021858996062536,-0.21069198107111778,-0.8224884824164258,-0.08346773549046786,0.07709858202158607,-0.3347891111209767,-0.5247270553377439,-0.05392097012398126,-0.20783234800975595,-0.018626752648998664,0.04524432021030166,0.11351828994636996,-0.4274756204245057,0.35243966079249345,0.5662010105390634,-0.10486905438093105,0.15177209832970556,6.03011803522605e-05,0.03650360784859915,-0.7694951651918046,-0.2443587814146048,0.0008685648478534997]\n",
      "Intercept:  -8.311975875206434\n"
     ]
    }
   ],
   "source": [
    "# Display model coefficients and intercept\n",
    "print(\"Coefficients: \", model.weights)\n",
    "print(\"Intercept: \", model.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions_rdd):\n",
    "    correct = predictions_rdd.filter(lambda x: x[0] == x[1]).count()\n",
    "    total = predictions_rdd.count()\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "def compute_precision(predictions_rdd, label):\n",
    "    true_positive = predictions_rdd.filter(lambda x: x[0] == label and x[1] == label).count()\n",
    "    predicted_positive = predictions_rdd.filter(lambda x: x[0] == label).count()\n",
    "    return true_positive / predicted_positive if predicted_positive > 0 else 0.0\n",
    "\n",
    "def compute_recall(predictions_rdd, label):\n",
    "    true_positive = predictions_rdd.filter(lambda x: x[0] == label and x[1] == label).count()\n",
    "    actual_positive = predictions_rdd.filter(lambda x: x[1] == label).count()\n",
    "    return true_positive / actual_positive if actual_positive > 0 else 0.0\n",
    "\n",
    "def compute_auc(predictions_rdd):\n",
    "    n_pos = predictions_rdd.filter(lambda x: x[1] == 1).count()\n",
    "    n_neg = predictions_rdd.filter(lambda x: x[1] == 0).count()\n",
    "    if n_pos == 0 or n_neg == 0:\n",
    "        return 0.0\n",
    "\n",
    "    data = predictions_rdd.collect()\n",
    "    data.sort(key=lambda x: x[0])\n",
    "    \n",
    "    rank_sum = 0.0\n",
    "    rank = 1\n",
    "    i = 0\n",
    "    while i < len(data):\n",
    "        j = i\n",
    "\n",
    "        while j < len(data) and data[j][0] == data[i][0]:\n",
    "            j += 1\n",
    "        group_size = j - i\n",
    "        avg_rank = (2 * rank + group_size - 1) / 2.0\n",
    "        for k in range(i, j):\n",
    "            if data[k][1] == 1:\n",
    "                rank_sum += avg_rank\n",
    "        rank += group_size\n",
    "        i = j\n",
    "\n",
    "    return (rank_sum - (n_pos * (n_pos + 1) / 2.0)) / (n_pos * n_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9991568000562133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision:  [0.999314083708169, 0.8671586715867159]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall:  [0.9998416280635072, 0.6010230179028133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:===>                                                   (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC:  0.8004323229831602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on training data\n",
    "predictions_train = train_rdd.map(lambda p: (model.predict(p.features), p.label))\n",
    "\n",
    "print(\"Train Accuracy:\", compute_accuracy(predictions_train))\n",
    "print(\"Train Precision: \", [compute_precision(predictions_train, label) for label in [0, 1]])\n",
    "print(\"Train Recall: \", [compute_recall(predictions_train, label) for label in [0, 1]])\n",
    "print(\"Train AUC: \", compute_auc(predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9992469747648985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision:  [0.9993337424388533, 0.9264705882352942]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall:  [0.9999122837795165, 0.6237623762376238]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 142:>                                                      (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC:  0.8118373300085702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on test data\n",
    "predictions_test = test_rdd.map(lambda p: (model.predict(p.features), p.label))\n",
    "\n",
    "print(\"Test Accuracy:\", compute_accuracy(predictions_test))\n",
    "print(\"Test Precision: \", [compute_precision(predictions_test, label) for label in [0, 1]])\n",
    "print(\"Test Recall: \", [compute_recall(predictions_test, label) for label in [0, 1]])\n",
    "print(\"Test AUC: \", compute_auc(predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
