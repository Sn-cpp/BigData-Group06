{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, RDD, SparkConf\n",
    "from math import exp, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([0.0,\n",
       "   -1.3598071336738,\n",
       "   -0.0727811733098497,\n",
       "   2.53634673796914,\n",
       "   1.37815522427443,\n",
       "   -0.338320769942518,\n",
       "   0.462387777762292,\n",
       "   0.239598554061257,\n",
       "   0.0986979012610507,\n",
       "   0.363786969611213,\n",
       "   0.0907941719789316,\n",
       "   -0.551599533260813,\n",
       "   -0.617800855762348,\n",
       "   -0.991389847235408,\n",
       "   -0.311169353699879,\n",
       "   1.46817697209427,\n",
       "   -0.470400525259478,\n",
       "   0.207971241929242,\n",
       "   0.0257905801985591,\n",
       "   0.403992960255733,\n",
       "   0.251412098239705,\n",
       "   -0.018306777944153,\n",
       "   0.277837575558899,\n",
       "   -0.110473910188767,\n",
       "   0.0669280749146731,\n",
       "   0.128539358273528,\n",
       "   -0.189114843888824,\n",
       "   0.133558376740387,\n",
       "   -0.0210530534538215,\n",
       "   149.62],\n",
       "  0.0),\n",
       " ([0.0,\n",
       "   1.19185711131486,\n",
       "   0.26615071205963,\n",
       "   0.16648011335321,\n",
       "   0.448154078460911,\n",
       "   0.0600176492822243,\n",
       "   -0.0823608088155687,\n",
       "   -0.0788029833323113,\n",
       "   0.0851016549148104,\n",
       "   -0.255425128109186,\n",
       "   -0.166974414004614,\n",
       "   1.61272666105479,\n",
       "   1.06523531137287,\n",
       "   0.48909501589608,\n",
       "   -0.143772296441519,\n",
       "   0.635558093258208,\n",
       "   0.463917041022171,\n",
       "   -0.114804663102346,\n",
       "   -0.183361270123994,\n",
       "   -0.145783041325259,\n",
       "   -0.0690831352230203,\n",
       "   -0.225775248033138,\n",
       "   -0.638671952771851,\n",
       "   0.101288021253234,\n",
       "   -0.339846475529127,\n",
       "   0.167170404418143,\n",
       "   0.125894532368176,\n",
       "   -0.00898309914322813,\n",
       "   0.0147241691924927,\n",
       "   2.69],\n",
       "  0.0),\n",
       " ([1.0,\n",
       "   -1.35835406159823,\n",
       "   -1.34016307473609,\n",
       "   1.77320934263119,\n",
       "   0.379779593034328,\n",
       "   -0.503198133318193,\n",
       "   1.80049938079263,\n",
       "   0.791460956450422,\n",
       "   0.247675786588991,\n",
       "   -1.51465432260583,\n",
       "   0.207642865216696,\n",
       "   0.624501459424895,\n",
       "   0.066083685268831,\n",
       "   0.717292731410831,\n",
       "   -0.165945922763554,\n",
       "   2.34586494901581,\n",
       "   -2.89008319444231,\n",
       "   1.10996937869599,\n",
       "   -0.121359313195888,\n",
       "   -2.26185709530414,\n",
       "   0.524979725224404,\n",
       "   0.247998153469754,\n",
       "   0.771679401917229,\n",
       "   0.909412262347719,\n",
       "   -0.689280956490685,\n",
       "   -0.327641833735251,\n",
       "   -0.139096571514147,\n",
       "   -0.0553527940384261,\n",
       "   -0.0597518405929204,\n",
       "   378.66],\n",
       "  0.0),\n",
       " ([1.0,\n",
       "   -0.966271711572087,\n",
       "   -0.185226008082898,\n",
       "   1.79299333957872,\n",
       "   -0.863291275036453,\n",
       "   -0.0103088796030823,\n",
       "   1.24720316752486,\n",
       "   0.23760893977178,\n",
       "   0.377435874652262,\n",
       "   -1.38702406270197,\n",
       "   -0.0549519224713749,\n",
       "   -0.226487263835401,\n",
       "   0.178228225877303,\n",
       "   0.507756869957169,\n",
       "   -0.28792374549456,\n",
       "   -0.631418117709045,\n",
       "   -1.0596472454325,\n",
       "   -0.684092786345479,\n",
       "   1.96577500349538,\n",
       "   -1.2326219700892,\n",
       "   -0.208037781160366,\n",
       "   -0.108300452035545,\n",
       "   0.00527359678253453,\n",
       "   -0.190320518742841,\n",
       "   -1.17557533186321,\n",
       "   0.647376034602038,\n",
       "   -0.221928844458407,\n",
       "   0.0627228487293033,\n",
       "   0.0614576285006353,\n",
       "   123.5],\n",
       "  0.0),\n",
       " ([2.0,\n",
       "   -1.15823309349523,\n",
       "   0.877736754848451,\n",
       "   1.548717846511,\n",
       "   0.403033933955121,\n",
       "   -0.407193377311653,\n",
       "   0.0959214624684256,\n",
       "   0.592940745385545,\n",
       "   -0.270532677192282,\n",
       "   0.817739308235294,\n",
       "   0.753074431976354,\n",
       "   -0.822842877946363,\n",
       "   0.53819555014995,\n",
       "   1.3458515932154,\n",
       "   -1.11966983471731,\n",
       "   0.175121130008994,\n",
       "   -0.451449182813529,\n",
       "   -0.237033239362776,\n",
       "   -0.0381947870352842,\n",
       "   0.803486924960175,\n",
       "   0.408542360392758,\n",
       "   -0.00943069713232919,\n",
       "   0.79827849458971,\n",
       "   -0.137458079619063,\n",
       "   0.141266983824769,\n",
       "   -0.206009587619756,\n",
       "   0.502292224181569,\n",
       "   0.219422229513348,\n",
       "   0.215153147499206,\n",
       "   69.99],\n",
       "  0.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the config for spark to enhance performance\n",
    "config = SparkConf()\\\n",
    "            .set(\"spark.driver.memory\", \"4g\")\\\n",
    "            .set(\"spark.executor.memory\", \"4g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/04/11 23:50:22 WARN Utils: Your hostname, DESKTOP-0H87CFM resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/11 23:50:22 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/11 23:50:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/11 23:50:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName='creditcard_lowlevel', conf=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef034b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing sets\n",
    "\n",
    "train_size = 0.8\n",
    "train_rdd, test_rdd = data_rdd.randomSplit([train_size, 1 - train_size], seed=24)\n",
    "\n",
    "# Compute mean and std for Time and Amount from training data\n",
    "#times = train_rdd.map(lambda x: x[0][0])  # Time is the first feature\n",
    "#amounts = train_rdd.map(lambda x: x[0][-1])  # Amount is the last feature\n",
    "#mean_time, std_time = times.mean(), times.stdev()\n",
    "#mean_amount, std_amount = amounts.mean(), amounts.stdev()\n",
    "\n",
    "# Function to scale Time and Amount\n",
    "#def scale_features(features, mean_time, std_time, mean_amount, std_amount):\n",
    "#    scaled_time = (features[0] - mean_time) / std_time\n",
    "#    scaled_amount = (features[-1] - mean_amount) / std_amount\n",
    "#    return [scaled_time] + features[1:-1] + [scaled_amount]\n",
    "\n",
    "# Apply scaling to training and testing data\n",
    "#train_rdd_scaled = train_rdd.map(lambda x: (scale_features(x[0], mean_time, std_time, mean_amount, std_amount), x[1]))\n",
    "#test_rdd_scaled = test_rdd.map(lambda x: (scale_features(x[0], mean_time, std_time, mean_amount, std_amount), x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad797a",
   "metadata": {},
   "source": [
    "## Define function for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51aedeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def _add_bias(self, features):\n",
    "        return features + [1.0]\n",
    "\n",
    "    def dot_product(self, features, weights):\n",
    "        return sum(f * w for f, w in zip(features, weights))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        try:\n",
    "            return 1.0 / (1.0 + math.exp(-z))\n",
    "        except OverflowError:\n",
    "            return 0.0 if z < 0 else 1.0\n",
    "\n",
    "    def compute_gradient(self, features, label, weights):\n",
    "        features = self._add_bias(features)\n",
    "        prediction = self.sigmoid(self.dot_product(features, weights))\n",
    "        error = prediction - label\n",
    "        return [error * x for x in features]\n",
    "\n",
    "    def predict(self, features):\n",
    "        features = self._add_bias(features)\n",
    "        prob = self.sigmoid(self.dot_product(features, self.weights))\n",
    "        return 1.0 if prob >= 0.5 else 0.0\n",
    "\n",
    "    def fit(self, data_rdd):\n",
    "        first_record = self._add_bias(data_rdd.first()[0])\n",
    "        n_features = len(first_record)\n",
    "        self.weights = [0.0] * n_features\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            gradient = data_rdd.map(\n",
    "                lambda x: self.compute_gradient(x[0], x[1], self.weights)\n",
    "            ).reduce(\n",
    "                lambda a, b: [a_i + b_i for a_i, b_i in zip(a, b)]\n",
    "            )\n",
    "            self.weights = [w - self.learning_rate * g for w, g in zip(self.weights, gradient)]\n",
    "\n",
    "    @property\n",
    "    def coefficients(self):\n",
    "        if self.weights:\n",
    "            return self.weights[:-1]\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def intercept(self):\n",
    "        if self.weights:\n",
    "            return self.weights[-1]\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704a65",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6df7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_iterations = 100\n",
    "\n",
    "log_reg = LogisticRegression(learning_rate=learning_rate, num_iterations=num_iterations)\n",
    "log_reg.fit(test_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67efdca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-18558517.814999912, -451.9070833575454, 323.1674373614058, -672.8055773984966, 420.7320930536979, -283.4986506079108, -161.39010681198297, -560.3240408390903, 97.11641769025482, -234.74305450674441, -553.9357980152168, 358.9380935161544, -603.3281433715642, -14.167436175648996, -665.9935910140988, -17.68501231608554, -406.01961603100364, -657.1762738153172, -216.51626850515333, 71.08733986780864, 21.791544144273484, 76.03649752811747, 4.797914556075549, -13.5525158444723, -7.889537254028329, -1.6964800574122842, 2.2398545271871435, 3.9624407886994786, 4.987548066183656, -18603.410049999766]\n",
      "Intercept:  -192.24999999999932\n"
     ]
    }
   ],
   "source": [
    "# Display model coefficients and intercept\n",
    "print(\"Coefficients: \", log_reg.coefficients)\n",
    "print(\"Intercept: \", log_reg.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62a42126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions_rdd):\n",
    "    correct = predictions_rdd.filter(lambda x: x[0] == x[1]).count()\n",
    "    total = predictions_rdd.count()\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "def compute_precision(predictions_rdd, label):\n",
    "    true_positive = predictions_rdd.filter(lambda x: x[0] == label and x[1] == label).count()\n",
    "    predicted_positive = predictions_rdd.filter(lambda x: x[0] == label).count()\n",
    "    return true_positive / predicted_positive if predicted_positive > 0 else 0.0\n",
    "\n",
    "def compute_recall(predictions_rdd, label):\n",
    "    true_positive = predictions_rdd.filter(lambda x: x[0] == label and x[1] == label).count()\n",
    "    actual_positive = predictions_rdd.filter(lambda x: x[1] == label).count()\n",
    "    return true_positive / actual_positive if actual_positive > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "422a20bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9982481328784626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision:  [0.9982481328784626, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 112:===========>                                             (1 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall:  [1.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on training data\n",
    "predictions_train = train_rdd.map(lambda p: (log_reg.predict(p[0]), p[1]))\n",
    "\n",
    "print(\"Train Accuracy:\", compute_accuracy(predictions_train))\n",
    "print(\"Train Precision: \", [compute_precision(predictions_train, label) for label in [0, 1]])\n",
    "print(\"Train Recall: \", [compute_recall(predictions_train, label) for label in [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3618ad4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9983698510078878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision:  [0.9983698510078878, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall:  [1.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on test data\n",
    "predictions_test = test_rdd.map(lambda p: (log_reg.predict(p[0]), p[1]))\n",
    "\n",
    "print(\"Test Accuracy:\", compute_accuracy(predictions_test))\n",
    "print(\"Test Precision: \", [compute_precision(predictions_test, label) for label in [0, 1]])\n",
    "print(\"Test Recall: \", [compute_recall(predictions_test, label) for label in [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a785fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e6b93",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrjob_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
