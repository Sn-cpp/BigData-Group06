{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adaaf9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import csv\n",
    "from io import StringIO\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba6dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the config for spark to enhance performance\n",
    "config = SparkConf()\\\n",
    "            .set(\"spark.driver.memory\", \"4g\")\\\n",
    "            .set(\"spark.executor.memory\", \"4g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd31659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/04/12 22:09:55 WARN Utils: Your hostname, minhnhat resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/04/12 22:09:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/12 22:09:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(appName='creditcard_lowlevel', conf=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b621145",
   "metadata": {},
   "source": [
    "## Parse input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e8b272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def parse_line(line):\n",
    "    return next(csv.reader(StringIO(line)))\n",
    "\n",
    "raw_rdd = sc.textFile(\"creditcard.csv\")\n",
    "header = raw_rdd.first() \n",
    "data_rdd = raw_rdd.filter(lambda line: line != header) \\\n",
    "                  .map(parse_line) \\\n",
    "                  .map(lambda row: [float(x) for x in row]) \\\n",
    "                  .map(lambda row: (row[:-1], row[-1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef034b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing sets\n",
    "train_size = 0.8\n",
    "train_rdd, test_rdd = data_rdd.randomSplit([train_size, 1 - train_size], seed=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad797a",
   "metadata": {},
   "source": [
    "## Define function for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51aedeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "\n",
    "    def _add_bias(self, features):\n",
    "        return features + [1.0]\n",
    "\n",
    "    def dot_product(self, features, weights):\n",
    "        return sum(f * w for f, w in zip(features, weights))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        try:\n",
    "            return 1.0 / (1.0 + math.exp(-z))\n",
    "        except OverflowError:\n",
    "            return 0.0 if z < 0 else 1.0\n",
    "\n",
    "    def compute_gradient(self, features, label, weights):\n",
    "        features = self._add_bias(features)\n",
    "        prediction = self.sigmoid(self.dot_product(features, weights))\n",
    "        error = prediction - label\n",
    "        return [error * x for x in features]\n",
    "\n",
    "    def predict(self, features):\n",
    "        features = self._add_bias(features)\n",
    "        prob = self.sigmoid(self.dot_product(features, self.weights))\n",
    "        return 1.0 if prob >= 0.5 else 0.0\n",
    "\n",
    "    def fit(self, data_rdd):\n",
    "        first_record = self._add_bias(data_rdd.first()[0])\n",
    "        n_features = len(first_record)\n",
    "        self.weights = [0.0] * n_features\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            gradient = data_rdd.map(\n",
    "                lambda x: self.compute_gradient(x[0], x[1], self.weights)\n",
    "            ).reduce(\n",
    "                lambda a, b: [a_i + b_i for a_i, b_i in zip(a, b)]\n",
    "            )\n",
    "            self.weights = [w - self.learning_rate * g for w, g in zip(self.weights, gradient)]\n",
    "\n",
    "    @property\n",
    "    def coefficients(self):\n",
    "        if self.weights:\n",
    "            return self.weights[:-1]\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def intercept(self):\n",
    "        if self.weights:\n",
    "            return self.weights[-1]\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704a65",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6df7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01 \n",
    "num_iterations = 20\n",
    "\n",
    "log_reg = LogisticRegression(learning_rate=learning_rate, num_iterations=num_iterations)\n",
    "log_reg.fit(train_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67efdca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-25393714.614999983, -90.26964798832012, 64.33602612889246, -137.09278453798973, 85.48357804966686, -56.39250697888101, -31.311152800252938, -112.91279753740908, 19.232147295830192, -46.88656278853463, -110.66616849556625, 72.49988894211533, -122.3967840808258, -2.1339775209086533, -129.85055139574962, -2.7888253881343488, -81.72940989200954, -131.522031517476, -43.243275001845355, 13.586343460879762, 3.3420234031935663, 14.916243632360867, 0.9985570692958942, -2.3292528479761527, -1.6482545033412652, 0.534583406466673, 0.38999401263095357, 1.2195822228369448, 0.898262787700131, -23834.346049999695]\n",
      "Intercept:  -266.64999999999986\n"
     ]
    }
   ],
   "source": [
    "# Display model coefficients and intercept\n",
    "print(\"Coefficients: \", log_reg.coefficients)\n",
    "print(\"Intercept: \", log_reg.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e77a3",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62a42126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions_rdd):\n",
    "    correct = predictions_rdd.filter(lambda x: x[0] == x[1]).count()\n",
    "    total = predictions_rdd.count()\n",
    "    return correct / total if total > 0 else 0.0\n",
    "\n",
    "def compute_precision(predictions_rdd, label):\n",
    "    tp = predictions_rdd.filter(lambda x: x[0] == label and x[1] == label).count()\n",
    "    pred_pos = predictions_rdd.filter(lambda x: x[0] == label).count()\n",
    "    return tp / pred_pos if pred_pos > 0 else 0.0\n",
    "\n",
    "def compute_recall(predictions_rdd, label):\n",
    "    tp = predictions_rdd.filter(lambda x: x[0] == label and x[1] == label).count()\n",
    "    actual_pos = predictions_rdd.filter(lambda x: x[1] == label).count()\n",
    "    return tp / actual_pos if actual_pos > 0 else 0.0\n",
    "\n",
    "def compute_auc(predictions_rdd):\n",
    "    n_pos = predictions_rdd.filter(lambda x: x[1] == 1).count()\n",
    "    n_neg = predictions_rdd.filter(lambda x: x[1] == 0).count()\n",
    "    if n_pos == 0 or n_neg == 0:\n",
    "        return 0.0\n",
    "    data = predictions_rdd.collect()\n",
    "    data.sort(key=lambda x: x[0])\n",
    "    rank_sum = 0.0\n",
    "    rank = 1\n",
    "    i = 0\n",
    "    while i < len(data):\n",
    "        j = i\n",
    "        while j < len(data) and data[j][0] == data[i][0]:\n",
    "            j += 1\n",
    "        group_size = j - i\n",
    "        avg_rank = (2 * rank + group_size - 1) / 2.0\n",
    "        for k in range(i, j):\n",
    "            if data[k][1] == 1:\n",
    "                rank_sum += avg_rank\n",
    "        rank += group_size\n",
    "        i = j\n",
    "    return (rank_sum - (n_pos * (n_pos + 1) / 2.0)) / (n_pos * n_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "422a20bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9982481328784626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision:  [0.9982481328784626, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Recall:  [1.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:===========>                                              (1 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on training data\n",
    "predictions_train = train_rdd.map(lambda p: (log_reg.predict(p[0]), p[1]))\n",
    "\n",
    "print(\"Train Accuracy:\", compute_accuracy(predictions_train))\n",
    "print(\"Train Precision: \", [compute_precision(predictions_train, label) for label in [0, 1]])\n",
    "print(\"Train Recall: \", [compute_recall(predictions_train, label) for label in [0, 1]])\n",
    "print(\"Train AUC:\", compute_auc(predictions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3618ad4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9983698510078878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision:  [0.9983698510078878, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Recall:  [1.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:===========>                                              (1 + 4) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Evaluate the model on test data\n",
    "predictions_test = test_rdd.map(lambda p: (log_reg.predict(p[0]), p[1]))\n",
    "\n",
    "print(\"Test Accuracy:\", compute_accuracy(predictions_test))\n",
    "print(\"Test Precision: \", [compute_precision(predictions_test, label) for label in [0, 1]])\n",
    "print(\"Test Recall: \", [compute_recall(predictions_test, label) for label in [0, 1]])\n",
    "print(\"Train AUC:\", compute_auc(predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a785fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the Spark session\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
