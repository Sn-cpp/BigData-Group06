{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor using Pyspark MLLib's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.mllib.feature import LabeledPoint\n",
    "\n",
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's initialize a Spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = SparkSession.Builder().appName('taxi_duration_mllib')\n",
    "spark = builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read input datasets for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Read input files\n",
    "raw_train_data = spark.read.csv('train.csv', header=True, inferSchema=True)\n",
    "raw_test_data = spark.read.csv('test.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse timestamp features in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cast the pickup string values of training data into timestamps.\n",
    "casted_train_data = raw_train_data.withColumns({\n",
    "                        'pickup_datetime' : raw_train_data['pickup_datetime'].cast('timestamp'),\n",
    "                    })\n",
    "\n",
    "#Cast the pickup string values of testing data into timestamps.\n",
    "casted_test_data = raw_test_data.withColumns({\n",
    "                        'pickup_datetime' : raw_test_data['pickup_datetime'].cast('timestamp')\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract usable features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get usable columns from the dataframe\n",
    "#Also convert timestamps into time elements and encode `store_and_fwd_flag` feature into binary values\n",
    "extracted_train_df = casted_train_data.selectExpr(\n",
    "        'vendor_id',\n",
    "        'YEAR(pickup_datetime)    AS pickup_year',\n",
    "        'MONTH(pickup_datetime)   AS pickup_month',\n",
    "        'DAY(pickup_datetime)     AS pickup_day',\n",
    "        'HOUR(pickup_datetime)    AS pickup_hour',\n",
    "        'MINUTE(pickup_datetime)  AS pickup_min',\n",
    "        'SECOND(pickup_datetime)  AS pickup_sec',\n",
    "        'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "        'CASE WHEN store_and_fwd_flag == \"Y\" THEN 1 ELSE 0 END AS store_and_fwd_flag',\n",
    "        'trip_duration'\n",
    "    )\n",
    "\n",
    "extracted_test_df = casted_test_data.selectExpr(\n",
    "        'vendor_id',\n",
    "        'YEAR(pickup_datetime)    AS pickup_year',\n",
    "        'MONTH(pickup_datetime)   AS pickup_month',\n",
    "        'DAY(pickup_datetime)     AS pickup_day',\n",
    "        'HOUR(pickup_datetime)    AS pickup_hour',\n",
    "        'MINUTE(pickup_datetime)  AS pickup_min',\n",
    "        'SECOND(pickup_datetime)  AS pickup_sec',\n",
    "        'passenger_count', 'pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
    "        'CASE WHEN store_and_fwd_flag == \"Y\" THEN 1 ELSE 0 END AS store_and_fwd_flag',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, convert the dataset into a RDD of `LabeledPoint` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to rdd\n",
    "train_data = extracted_train_df.rdd.map(lambda row: LabeledPoint(label= row[-1], features= row[:-1]) )\n",
    "test_data = extracted_test_df.rdd.map(lambda row: LabeledPoint(label= float('-inf'), features= row[:-1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and testing sets\n",
    "\n",
    "###training set proportion parameter:\n",
    "train_size = 0.8\n",
    "###\n",
    "\n",
    "train, test = train_data.randomSplit([train_size, 1 - train_size], seed=24) #Fixed with seed for reproductivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = DecisionTree.trainRegressor(train, categoricalFeaturesInfo={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test.map(lambda row: row.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = test.map(lambda row: row.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(663.0, 805.3417864433612)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pred.first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrjob_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
